{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b5837b0-5ccf-4b71-882e-ed06d8137e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb4ae9a4-204c-41d9-b90d-008510b77e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15876621007919312,\n",
       " 0.15903350710868835,\n",
       " 0.17745572328567505,\n",
       " 0.16863788664340973]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "a = torch.rand(4,10,20)\n",
    "b = torch.rand(4,10,20)\n",
    "loss = nn.MSELoss()\n",
    "[loss(x,y).item() for x,y in zip(a,b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a18c113-104a-449e-b97e-3de7b373007f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(list(range(10)))\n",
    "np.std(list(range(10)))\n",
    "np.quantile(list(range(10)),0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93331257-ec1f-40a6-a6f6-18907141f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from models import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d739b6c-e2ac-4dd1-9670-fa7433a7747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,config = get_model('ae0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ede67e-c904-46e6-ae1a-a56bcc81ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "exam_code = '''\n",
    "e.g)  \n",
    "python evaluate.py -p ./ae/models/ae0_80.pt\n",
    "'''\n",
    "parser = argparse.ArgumentParser(\"Evaluate AE models\",epilog=exam_code)   \n",
    "\n",
    "\n",
    "parser.add_argument('-d'  ,'--directory'   ,default='models' ,metavar='{...}'    ,help='directory path containing the models')\n",
    "parser.add_argument('-p'  ,'--path'      ,default=None       , help='Specify the model path')\n",
    "parser.add_argument('-th',default=None,help='Value of threshold to classify')\n",
    "parser.add_argument('--dataset_path'      ,default='./data/split/test.csv'  , help='test dataset path')\n",
    "parser.add_argument('-s','--save'         ,default=True, type=bool  , help='whether to save')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bddf2e-7998-42d7-8c4c-a62653585109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataset import ProteinDataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import recall_score \n",
    "from sklearn.metrics import precision_score \n",
    "from sklearn.metrics import f1_score \n",
    "# from sklearn.metrics import make_scorer\n",
    "# from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "def evaluate(dl,model,lossf,epoch=None):\n",
    "    model.eval()\n",
    "    size, _ , losses = len(dl.dataset) ,0,0\n",
    "    pre_l,gt_l = [],[]\n",
    "    with torch.no_grad():\n",
    "        for x,y in dl:\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            pre = model(x)\n",
    "            loss = lossf(pre,y)\n",
    "            \n",
    "            losses += loss.item()\n",
    "            pre_l.extend(pre.argmax(1).cpu().numpy().tolist())\n",
    "            gt_l .extend(y.cpu().numpy().tolist())\n",
    "    \n",
    "    loss     = losses/size\n",
    "    acc      = accuracy_score(gt_l,pre_l)\n",
    "    recall   = recall_score(gt_l,pre_l)\n",
    "    precision= precision_score(gt_l,pre_l)\n",
    "    f1       = f1_score(gt_l,pre_l)\n",
    "    confusion= confusion_matrix(gt_l,pre_l)\n",
    "\n",
    "    metrics = {'acc':acc,'recall':recall,'precision':precision,'f1':f1,'confusion':confusion,'loss':loss}\n",
    "    return metrics\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "from models import *\n",
    "import os\n",
    "results = {}\n",
    "model_paths = []\n",
    "if args.path is not None:\n",
    "    m_path = args.path\n",
    "    model_paths.append(m_path)\n",
    "    model_name = os.path.basename(m_path).split('_')[0].lower()\n",
    "    print(model_name)\n",
    "    # model = 'lstm0'\n",
    "    model,transform = get_model(model_name)\n",
    "    model = model.to(device)\n",
    "\n",
    "     # config\n",
    "    transform = config['transform'] \n",
    "    batch_size = config['batch_size']\n",
    "\n",
    "    tedt  = ProteinDataset(args.dataset_path,transform=transform)\n",
    "    tedl  = torch.utils.data.DataLoader(tedt, batch_size=batch_size, num_workers=4)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    opt  = torch.optim.Adam(params)\n",
    "\n",
    "    \n",
    "    model.load_state_dict(torch.load(m_path))\n",
    "    \n",
    "    result = evaluate(tedl,model,loss)\n",
    "    \n",
    "    print(f'{model_name}: {result}')\n",
    "    results[model_name] = result\n",
    "\n",
    "else:\n",
    "    files = os.listdir(args.directory)\n",
    "    model_paths = [os.path.join('./models',file) for file in files if file.endswith('.pt')]\n",
    "    \n",
    "    for m_path in model_paths:\n",
    "        model_name = os.path.basename(m_path).split('_')[0].lower()\n",
    "        \n",
    "        print(model_name)\n",
    "        model,config = get_model(model_name)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # config\n",
    "        transform = config['transform'] \n",
    "        batch_size = config['batch_size']\n",
    "        \n",
    "        tedt  = ProteinDataset(args.dataset_path,transform=transform)\n",
    "        tedl  = torch.utils.data.DataLoader(tedt, batch_size=batch_size, num_workers=4)\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        params = [p for p in model.parameters() if p.requires_grad]\n",
    "        opt  = torch.optim.Adam(params)\n",
    "\n",
    "        model.load_state_dict(torch.load(m_path))\n",
    "\n",
    "        result = evaluate(tedl,model,loss)\n",
    "\n",
    "        print(f'{model_name}: {result}')\n",
    "        results[model_name] = result\n",
    "# save the results\n",
    "print(type(args.save ))\n",
    "if args.save:\n",
    "    import pandas as pd\n",
    "    df  = pd.DataFrame(results).T\n",
    "    models = [os.path.splitext( os.path.basename(path) )[0] for path in model_paths]\n",
    "    df.to_csv(f\"assets/{'&'.join(models)}.csv\")\n",
    "    print(f\"result was saved in assets/{'&'.join(models)}.csv\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
